{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyQJXyqufts5QSAVMfLT6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarakantaacharya/Data_Analyst_Internship_Capx/blob/main/model_training_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Model Training"
      ],
      "metadata": {
        "id": "EtNq1e6806iW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instructions :"
      ],
      "metadata": {
        "id": "s01wK8Tk4fW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Run the Code for Model Training**\n",
        "\n",
        "1. **Install Dependencies**:\n",
        "   - Before running the code, ensure that you have installed all the required libraries. You can do this by installing the necessary packages via the `requirements.txt` file:\n",
        "   \n",
        "   ```bash\n",
        "   pip install -r requirements.txt\n",
        "   ```\n",
        "\n",
        "2. **Prepare the Data**:\n",
        "   - Make sure you have completed the **data scraping** and **data preprocessing** steps to generate the `reddit_stock_data_posts_cleaned.csv` file. This file will be used as input for model training.\n",
        "   \n",
        "   If you haven’t already done this, refer to the earlier sections where you scraped and preprocessed the data.\n",
        "\n",
        "3. **Run the Model Training Script**:\n",
        "   - Once the dependencies are installed and the data is prepared, run the model training script:\n",
        "   \n",
        "   ```bash\n",
        "   python model_training.py\n",
        "   ```\n",
        "\n",
        "4. **Monitor Model Training**:\n",
        "   - As the script runs, it will train a machine learning model (e.g., Logistic Regression) using the preprocessed data.\n",
        "   - You will see evaluation metrics such as **accuracy**, **precision**, **recall**, and **F1-score** printed to the terminal.\n",
        "\n",
        "5. **Review Output**:\n",
        "   - After the model is trained, review the printed output for evaluation metrics to determine how well the model is performing.\n",
        "   - If the results are satisfactory, you can proceed to save the model or use it for predictions. If needed, you may want to fine-tune the model.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8VCUMf4sbFpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Demonstration Steps for Model Training**\n",
        "\n",
        "\n",
        "#### **1. Set up Environment**\n",
        "   - **Install Dependencies**: First, ensure all required libraries are installed by running the following command:\n",
        "\n",
        "   ```bash\n",
        "   pip install -r requirements.txt\n",
        "   ```\n",
        "\n",
        "#### **2. Data Preprocessing**\n",
        "   - The model training script relies on preprocessed data. If you haven't already run the data scraping and preprocessing scripts, ensure that you do so to generate the cleaned data (`reddit_stock_data_posts_cleaned.csv`).\n",
        "\n",
        "#### **3. Model Training Script Execution**\n",
        "   - Once the data is prepared, navigate to the folder containing the model training script (e.g., `model_training.py`).\n",
        "   - Open a terminal or command prompt in that folder and run the following command:\n",
        "\n",
        "   ```bash\n",
        "   python model_training.py\n",
        "   ```\n",
        "\n",
        "   - This will start the execution of the script, which will load the preprocessed data, split it into training and testing sets, and train the machine learning model.\n",
        "\n",
        "#### **4. Monitoring Model Training**\n",
        "   - As the script runs, you will see output in the terminal. This output will show information about:\n",
        "     - The data being loaded and preprocessed.\n",
        "     - The splitting of data into **features (X)** and **target variable (y)**.\n",
        "     - The training process, where the model learns from the training data.\n",
        "   \n",
        "   - After the model is trained, the script will evaluate its performance using metrics such as **accuracy**, **precision**, **recall**, and **F1-score**. These metrics will give you insight into how well the model is performing.\n",
        "\n",
        "#### **5. Review the Results**\n",
        "   - Once the script has finished, it will output the evaluation results to the terminal, something like:\n",
        "\n",
        "   ```\n",
        "   Accuracy: 0.85\n",
        "   Precision: 0.87\n",
        "   Recall: 0.83\n",
        "   F1-score: 0.85\n",
        "   ```\n",
        "\n",
        "   These metrics show how well the model is predicting the sentiment of the Reddit posts and their relationship with stock price movements.\n",
        "\n",
        "   ```\n",
        "\n",
        "   Replace `new_data` with the data you want to predict on.\n",
        "\n",
        "#### **8. Final Steps**\n",
        "   - After the demonstration, ensure the results are saved (e.g., in the form of evaluation metrics and trained model) so that you can proceed with further analysis or use the trained model for future predictions.\n",
        "\n",
        "---\n",
        "\n",
        "These steps guide you through a demonstration of running the **Model Training** script. You'll first set up the environment, run the training, monitor the progress, and review the results to evaluate how well the model performs."
      ],
      "metadata": {
        "id": "cslnLKZ7biA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the TensorFlow library, which is essential for building and training deep learning models.\n",
        "!pip install tensorflow\n",
        "# Install the Scikeras library, which provides an interface to use Keras models within scikit-learn pipelines for easier machine learning integration.\n",
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ee5be4-0a49-4b3c-88db-04158d53ff79",
        "id": "EpO5Dsvo1d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.5.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Importing Libraries"
      ],
      "metadata": {
        "id": "vdx7J_e81QRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the pandas library for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Importing various classification algorithms from scikit-learn\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier  # Ensemble learning models\n",
        "from sklearn.linear_model import LogisticRegression  # Logistic regression model\n",
        "from sklearn.svm import SVC  # Support Vector Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  # K-Nearest Neighbors Classifier\n",
        "\n",
        "# Importing evaluation metrics to assess model performance\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Importing train_test_split for splitting the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing StandardScaler to standardize features by removing the mean and scaling to unit variance\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Importing TensorFlow's Keras library for building deep learning models\n",
        "from tensorflow.keras.models import Sequential  # Sequential API for building models layer by layer\n",
        "\n",
        "# Importing layers from Keras for building neural network architectures\n",
        "from keras.layers import Dense, Dropout, Input  # Dense: fully connected layers, Dropout: prevents overfitting\n",
        "\n",
        "# Importing Adam optimizer for training deep learning models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Importing KerasClassifier wrapper to use Keras models in scikit-learn pipelines\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Importing StratifiedKFold and cross_val_score for cross-validation\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score  # StratifiedKFold ensures balanced class distribution in splits\n",
        "\n",
        "# Importing visualization libraries\n",
        "from matplotlib import pyplot as plt  # For creating visualizations\n",
        "import seaborn as sns  # Advanced visualization library with aesthetic options\n",
        "\n",
        "# Importing train_test_split again (redundant here since already imported earlier)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing make_pipeline to create machine learning pipelines\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Importing StandardScaler again (redundant here since already imported earlier)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Creating an instance of StandardScaler for feature scaling\n",
        "scaler = StandardScaler()  # Standardizes features to have mean 0 and standard deviation 1"
      ],
      "metadata": {
        "id": "jHv1_y9m1Niq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target variable\n",
        "X_features = ['score', 'num_comments', 'upvote_ratio', 'title_sentiment_score',\n",
        "       'content_sentiment_score', 'Close_AAPL', 'Price_Change', 'Prev_Price_Change']\n",
        "\n",
        "X = model_df[X_features]  # Adjust features based on your data\n",
        "y = model_df['stock_direction']\n",
        "\n",
        "# Train-test split (60-40 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHnWY7f2x9_a",
        "outputId": "4dbea697-6d8d-4921-f2b4-c42bb9b4fdc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4502, 8)\n",
            "X_test shape: (3002, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_1 = pd.DataFrame()   #We create an empty dataframe to store the metric results"
      ],
      "metadata": {
        "id": "yTztaEoWZEXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Explanation of the models:\n",
        "1. Random Forest: A robust ensemble method that combines multiple decision trees to improve classification accuracy and reduce overfitting. class_weight='balanced' automatically adjusts class weights inversely proportional to their frequencies in the data.\n",
        "\n",
        "2. Gradient Boosting: Builds models sequentially, optimizing for residual errors. It's often used for competitive performance in structured data.\n",
        "\n",
        "3. AdaBoost: Combines weak classifiers iteratively to focus on misclassified instances. The SAMME algorithm supports multi-class outputs.\n",
        "\n",
        "4. Logistic Regression: A linear model used for binary/multi-class classification. Here, it's combined with StandardScaler for preprocessing, and saga is chosen for its efficiency on large datasets.\n",
        "\n",
        "5. Support Vector Machine (SVC): Useful for high-dimensional spaces and non-linear decision boundaries. The class_weight='balanced' adjusts for class imbalance.\n",
        "\n",
        "6. K-Nearest Neighbors: Simple and intuitive, relying on the proximity of data points. The choice of n_neighbors=5 is a common default, but it can be tuned.\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "\n",
        "#####Additional Notes:\n",
        "1. Class weights: Models like Random Forest, SVC, and Logistic Regression are set with class_weight='balanced' to handle datasets with imbalanced target distributions effectively.\n",
        "2. Random State: Ensures reproducibility for models that involve randomness.\n",
        "Pipelines: Used for Logistic Regression to combine preprocessing (scaling) and modeling into a single step."
      ],
      "metadata": {
        "id": "2LJNvo71uCgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing a dictionary of machine learning models with specific hyperparameters\n",
        "models = {\n",
        "    # Random Forest: Ensemble model using multiple decision trees, with 100 trees and balanced class weights\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=100,  # Number of decision trees\n",
        "        class_weight='balanced',  # Adjust weights for imbalanced classes\n",
        "        random_state=42  # Ensures reproducibility\n",
        "    ),\n",
        "\n",
        "    # Gradient Boosting: Ensemble model where trees are built sequentially to minimize errors\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
        "        n_estimators=100,  # Number of boosting stages\n",
        "        random_state=42  # Ensures reproducibility\n",
        "    ),\n",
        "\n",
        "    # AdaBoost: Boosting algorithm with SAMME (for multi-class classification)\n",
        "    \"AdaBoost\": AdaBoostClassifier(\n",
        "        algorithm='SAMME'  # Algorithm type, SAMME is suitable for multi-class problems\n",
        "    ),\n",
        "\n",
        "    # Logistic Regression: Linear model wrapped in a pipeline with scaling and custom parameters\n",
        "    'Logistic Regression': make_pipeline(\n",
        "        StandardScaler(),  # Standardizes features\n",
        "        LogisticRegression(\n",
        "            max_iter=3000,  # Maximum number of iterations for optimization\n",
        "            solver='saga',  # Solver suitable for large datasets and supports L1/L2 regularization\n",
        "            class_weight='balanced',  # Adjust weights for imbalanced classes\n",
        "            random_state=42  # Ensures reproducibility\n",
        "        )\n",
        "    ),\n",
        "\n",
        "    # Support Vector Machine: Non-linear classifier with kernel tricks\n",
        "    \"Support Vector Machine\": SVC(\n",
        "        class_weight='balanced',  # Adjust weights for imbalanced classes\n",
        "        random_state=42  # Ensures reproducibility\n",
        "    ),\n",
        "\n",
        "    # K-Nearest Neighbors: Distance-based algorithm, finding the 5 nearest neighbors\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(\n",
        "        n_neighbors=5  # Number of neighbors to consider\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "9VaIYKpWxstq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Explanation of the DNN:\n",
        "1. Input Layer: The Input layer specifies the shape of input data, which corresponds to the number of features in the dataset (X.shape[1]).\n",
        "\n",
        "2. Hidden Layers:\n",
        "\n",
        "    2.1 First hidden layer: 64 neurons, ReLU activation for non-linearity, followed by a Dropout layer to mitigate overfitting.\n",
        "\n",
        "    2.2 Second hidden layer: 32 neurons, ReLU activation, with another Dropout layer.\n",
        "\n",
        "3. Output Layer:\n",
        "A single neuron with a sigmoid activation function to output probabilities, suitable for binary classification.\n",
        "\n",
        "4. Model Compilation:\n",
        "\n",
        "    4.1 Optimizer: Adam is chosen for its adaptive learning rate and efficiency.\n",
        "\n",
        "    4.2 Loss function: Binary cross-entropy is appropriate for binary classification tasks.\n",
        "\n",
        "    4.3 Metrics: Accuracy is used to evaluate the model during training.\n",
        "\n",
        "#####Integration with scikit-learn:\n",
        "The KerasClassifier wrapper enables the DNN to integrate seamlessly into scikit-learn pipelines, making it compatible with functions like cross-validation and hyperparameter tuning.\n",
        "\n",
        "#####Adding to the models dictionary:\n",
        "The DNN model is added under the key \"Deep Neural Network\" to be evaluated alongside other machine learning models."
      ],
      "metadata": {
        "id": "Yiy5G5jkuh68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to build the Deep Neural Network (DNN) model\n",
        "def build_dnn():\n",
        "    # Define the model structure using Keras Sequential API\n",
        "    model = Sequential([\n",
        "        # Input layer: Automatically adjusts to the number of features in the dataset\n",
        "        Input(shape=(X.shape[1],)),  # Input layer with shape matching the number of features in X\n",
        "\n",
        "        # First hidden layer: 64 neurons with ReLU activation for non-linearity\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),  # Dropout layer to reduce overfitting by randomly dropping 20% of neurons\n",
        "\n",
        "        # Second hidden layer: 32 neurons with ReLU activation\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),  # Dropout for further regularization\n",
        "\n",
        "        # Output layer: 1 neuron with sigmoid activation for binary classification\n",
        "        Dense(1, activation='sigmoid')  # Outputs probability of the positive class\n",
        "    ])\n",
        "\n",
        "    # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),  # Optimizer with a learning rate of 0.001\n",
        "        loss='binary_crossentropy',  # Loss function for binary classification\n",
        "        metrics=['accuracy']  # Evaluation metric to track during training\n",
        "    )\n",
        "    return model  # Return the constructed model\n",
        "\n",
        "# Wrap the DNN model with KerasClassifier for compatibility with scikit-learn workflows\n",
        "dnn_model = KerasClassifier(\n",
        "    model=build_dnn,  # The function that defines the DNN architecture\n",
        "    epochs=25,  # Number of training epochs\n",
        "    batch_size=32,  # Mini-batch size for gradient updates\n",
        "    verbose=0  # Suppress training output\n",
        ")\n",
        "\n",
        "# Add the DNN model to the dictionary of models for evaluation\n",
        "models['Deep Neural Network'] = dnn_model"
      ],
      "metadata": {
        "id": "JZ-t4oDvdBZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here after defining the respective model ....\n",
        "In next step we will train the defined model with refined model_df dataset"
      ],
      "metadata": {
        "id": "LTwkFGj22hYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Training and Performance Metrics"
      ],
      "metadata": {
        "id": "dfXxb8EYbmmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,  # Calculates the ratio of correctly predicted instances to total instances\n",
        "    precision_score,  # Measures the proportion of true positive predictions out of all positive predictions\n",
        "    recall_score,  # Measures the proportion of true positives identified out of all actual positives\n",
        "    f1_score,  # Harmonic mean of precision and recall, balancing the two metrics\n",
        "    confusion_matrix,  # Summarizes prediction results as a matrix of True Positives, False Positives, etc.\n",
        "    classification_report,  # Generates a detailed report including precision, recall, f1-score, and support\n",
        "    roc_auc_score,  # Computes the Area Under the Receiver Operating Characteristic Curve (ROC AUC)\n",
        "    roc_curve,  # Calculates the Receiver Operating Characteristic curve data (TPR vs. FPR)\n",
        "    matthews_corrcoef  # Measures the quality of binary classifications with a balanced metric\n",
        ")"
      ],
      "metadata": {
        "id": "O4LbJbczrj-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Explanation of Metrics:\n",
        "\n",
        "1. Accuracy:\n",
        "\n",
        "    Represents the overall correctness of the model's predictions.\n",
        "Best suited when the dataset is balanced.\n",
        "\n",
        "2. Precision:\n",
        "\n",
        "    High precision means a low false positive rate.\n",
        "    Useful when false positives are more costly than false negatives.\n",
        "3. Recall:\n",
        "\n",
        "    Also known as sensitivity or true positive rate.\n",
        "    Important in scenarios where missing a positive case is costly (e.g., medical diagnoses).\n",
        "4. F1-Score:\n",
        "\n",
        "    Combines precision and recall into a single metric, particularly useful for imbalanced datasets.\n",
        "    A high F1-score indicates a good balance between precision and recall.\n",
        "5. Confusion Matrix:\n",
        "\n",
        "    A matrix summarizing true positives, true negatives, false positives, and false negatives.\n",
        "    Provides a comprehensive view of prediction errors.\n",
        "6. Classification Report:\n",
        "\n",
        "    Includes precision, recall, F1-score, and support (number of true instances for each class).\n",
        "    Useful for understanding model performance across all classes.\n",
        "7. ROC AUC:\n",
        "\n",
        "    Measures the ability of the classifier to distinguish between classes.\n",
        "    A value closer to 1 indicates better performance.\n",
        "8. ROC Curve:\n",
        "\n",
        "    Plots the true positive rate (TPR) against the false positive rate (FPR) at various thresholds.\n",
        "    Visual representation of classifier performance.\n",
        "9. Matthews Correlation Coefficient (MCC):\n",
        "\n",
        "    A balanced metric even for imbalanced datasets.\n",
        "    Values range from -1 (total disagreement) to +1 (perfect prediction).\n",
        "\n",
        "#####When to Use:\n",
        "1. Balanced datasets: Accuracy and F1-score.\n",
        "2. Imbalanced datasets: Precision, recall, ROC AUC, and MCC.\n",
        "3. Detailed analysis: Classification report and confusion matrix."
      ],
      "metadata": {
        "id": "j-qEdlSXvyQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "rQdrBSo7xChF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Feature Scaling:\n",
        "\n",
        "    -> Only applied to models like Logistic Regression, SVM, and KNN because they are sensitive to the scale of input features.\n",
        "\n",
        "    -> Ensemble models like Random Forest and Gradient Boosting do not require feature scaling.\n",
        "\n",
        "2. Metrics:\n",
        "\n",
        "    A wide range of metrics is calculated to provide a comprehensive evaluation of each model’s performance.\n",
        "\n",
        "    Special handling for models that lack predict_proba.\n",
        "\n",
        "3. Confusion Matrix:\n",
        "\n",
        "    Provides a granular view of model predictions in terms of True Positives, False Positives, True Negatives, and False Negatives.\n",
        "\n",
        "4. Classification Report:\n",
        "\n",
        "    Includes precision, recall, F1-score, and support for each class.\n",
        "\n",
        "5. Results Dictionary:\n",
        "\n",
        "    Each model's metrics are stored in a nested dictionary for easy conversion into a DataFrame for better readability.\n",
        "\n",
        "6. DataFrame Summary:\n",
        "\n",
        "    The results dictionary is converted into a DataFrame to provide a tabular summary of all models’ performances."
      ],
      "metadata": {
        "id": "gQBHiE4RwjEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store results of all models\n",
        "results = {}\n",
        "\n",
        "# Train each model and evaluate performance\n",
        "for name, model in models.items():\n",
        "    # Apply feature scaling for specific models that are sensitive to scale\n",
        "    if name == \"Logistic Regression\" or name == \"Support Vector Machine\" or name == \"K-Nearest Neighbors\":\n",
        "        X_train_ = scaler.fit_transform(X_train)  # Fit and transform the training data\n",
        "        X_test_ = scaler.transform(X_test)  # Transform the test data\n",
        "    else:\n",
        "        X_train_ = X_train  # Use raw data for other models\n",
        "        X_test_ = X_test\n",
        "\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_train_, y_train)\n",
        "\n",
        "    # Predict labels on the test data\n",
        "    y_pred = model.predict(X_test_)\n",
        "\n",
        "    # Predict probabilities if the model supports it\n",
        "    y_pred_proba = model.predict_proba(X_test_)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()  # Extract true negatives, false positives, false negatives, and true positives\n",
        "\n",
        "    # Calculate various performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)  # Overall accuracy\n",
        "    precision = precision_score(y_test, y_pred, zero_division=1)  # Precision (with zero-division handling)\n",
        "    recall = recall_score(y_test, y_pred)  # Sensitivity/Recall\n",
        "    f1 = f1_score(y_test, y_pred)  # F1-Score (harmonic mean of precision and recall)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Specificity: True Negative Rate\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None  # ROC AUC Score\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)  # Matthews Correlation Coefficient\n",
        "\n",
        "    # Store all metrics in the results dictionary\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall (Sensitivity)': recall,\n",
        "        'Specificity': specificity,\n",
        "        'F1-Score': f1,\n",
        "        'ROC AUC': roc_auc,\n",
        "        'MCC': mcc,\n",
        "        'Confusion Matrix': cm\n",
        "    }\n",
        "\n",
        "    # Print detailed metrics and reports for each model\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "    print(f\"Specificity: {specificity:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    if roc_auc is not None:\n",
        "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "    print(f\"MCC: {mcc:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=1))\n",
        "\n",
        "    # Convert the results dictionary into a DataFrame for better visualization\n",
        "    results_df_1 = pd.DataFrame(results).T\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# Display the consolidated DataFrame of results\n",
        "print(\"\\nSummary of Results 1:\")\n",
        "results_df_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QxNWVrB8zoCS",
        "outputId": "74a33ee4-ac69-4ddf-9bdb-261066f68a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 1.0000\n",
            "F1-Score: 1.0000\n",
            "ROC AUC: 1.0000\n",
            "MCC: 1.0000\n",
            "Confusion Matrix:\n",
            "[[1485    0]\n",
            " [   0 1517]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1485\n",
            "           1       1.00      1.00      1.00      1517\n",
            "\n",
            "    accuracy                           1.00      3002\n",
            "   macro avg       1.00      1.00      1.00      3002\n",
            "weighted avg       1.00      1.00      1.00      3002\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 1.0000\n",
            "F1-Score: 1.0000\n",
            "ROC AUC: 1.0000\n",
            "MCC: 1.0000\n",
            "Confusion Matrix:\n",
            "[[1485    0]\n",
            " [   0 1517]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1485\n",
            "           1       1.00      1.00      1.00      1517\n",
            "\n",
            "    accuracy                           1.00      3002\n",
            "   macro avg       1.00      1.00      1.00      3002\n",
            "weighted avg       1.00      1.00      1.00      3002\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "AdaBoost Results:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 1.0000\n",
            "F1-Score: 1.0000\n",
            "ROC AUC: 1.0000\n",
            "MCC: 1.0000\n",
            "Confusion Matrix:\n",
            "[[1485    0]\n",
            " [   0 1517]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1485\n",
            "           1       1.00      1.00      1.00      1517\n",
            "\n",
            "    accuracy                           1.00      3002\n",
            "   macro avg       1.00      1.00      1.00      3002\n",
            "weighted avg       1.00      1.00      1.00      3002\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.9890\n",
            "Precision: 0.9914\n",
            "Recall (Sensitivity): 0.9868\n",
            "Specificity: 0.9912\n",
            "F1-Score: 0.9891\n",
            "ROC AUC: 0.9996\n",
            "MCC: 0.9780\n",
            "Confusion Matrix:\n",
            "[[1472   13]\n",
            " [  20 1497]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1485\n",
            "           1       0.99      0.99      0.99      1517\n",
            "\n",
            "    accuracy                           0.99      3002\n",
            "   macro avg       0.99      0.99      0.99      3002\n",
            "weighted avg       0.99      0.99      0.99      3002\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Support Vector Machine Results:\n",
            "Accuracy: 0.9201\n",
            "Precision: 0.9265\n",
            "Recall (Sensitivity): 0.9143\n",
            "Specificity: 0.9259\n",
            "F1-Score: 0.9204\n",
            "MCC: 0.8402\n",
            "Confusion Matrix:\n",
            "[[1375  110]\n",
            " [ 130 1387]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92      1485\n",
            "           1       0.93      0.91      0.92      1517\n",
            "\n",
            "    accuracy                           0.92      3002\n",
            "   macro avg       0.92      0.92      0.92      3002\n",
            "weighted avg       0.92      0.92      0.92      3002\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "K-Nearest Neighbors Results:\n",
            "Accuracy: 0.7968\n",
            "Precision: 0.8001\n",
            "Recall (Sensitivity): 0.7970\n",
            "Specificity: 0.7966\n",
            "F1-Score: 0.7985\n",
            "ROC AUC: 0.8790\n",
            "MCC: 0.5936\n",
            "Confusion Matrix:\n",
            "[[1183  302]\n",
            " [ 308 1209]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.80      0.80      1485\n",
            "           1       0.80      0.80      0.80      1517\n",
            "\n",
            "    accuracy                           0.80      3002\n",
            "   macro avg       0.80      0.80      0.80      3002\n",
            "weighted avg       0.80      0.80      0.80      3002\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Deep Neural Network Results:\n",
            "Accuracy: 0.4947\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.0000\n",
            "Specificity: 1.0000\n",
            "F1-Score: 0.0000\n",
            "ROC AUC: 0.5000\n",
            "MCC: 0.0000\n",
            "Confusion Matrix:\n",
            "[[1485    0]\n",
            " [1517    0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      1.00      0.66      1485\n",
            "           1       1.00      0.00      0.00      1517\n",
            "\n",
            "    accuracy                           0.49      3002\n",
            "   macro avg       0.75      0.50      0.33      3002\n",
            "weighted avg       0.75      0.49      0.33      3002\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Summary of Results 1:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Accuracy Precision Recall (Sensitivity) Specificity  \\\n",
              "Random Forest                1.0       1.0                  1.0         1.0   \n",
              "Gradient Boosting            1.0       1.0                  1.0         1.0   \n",
              "AdaBoost                     1.0       1.0                  1.0         1.0   \n",
              "Logistic Regression     0.989007  0.991391             0.986816    0.991246   \n",
              "Support Vector Machine  0.920053   0.92652             0.914305    0.925926   \n",
              "K-Nearest Neighbors     0.796802  0.800132             0.796968    0.796633   \n",
              "Deep Neural Network      0.49467       1.0                  0.0         1.0   \n",
              "\n",
              "                        F1-Score   ROC AUC       MCC  \\\n",
              "Random Forest                1.0       1.0       1.0   \n",
              "Gradient Boosting            1.0       1.0       1.0   \n",
              "AdaBoost                     1.0       1.0       1.0   \n",
              "Logistic Regression     0.989098  0.999629  0.978024   \n",
              "Support Vector Machine  0.920372      None  0.840186   \n",
              "K-Nearest Neighbors     0.798547  0.878995   0.59358   \n",
              "Deep Neural Network          0.0       0.5       0.0   \n",
              "\n",
              "                                  Confusion Matrix  \n",
              "Random Forest               [[1485, 0], [0, 1517]]  \n",
              "Gradient Boosting           [[1485, 0], [0, 1517]]  \n",
              "AdaBoost                    [[1485, 0], [0, 1517]]  \n",
              "Logistic Regression       [[1472, 13], [20, 1497]]  \n",
              "Support Vector Machine  [[1375, 110], [130, 1387]]  \n",
              "K-Nearest Neighbors     [[1183, 302], [308, 1209]]  \n",
              "Deep Neural Network         [[1485, 0], [1517, 0]]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ddeddba-65ae-4d86-91a6-84605ccda847\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall (Sensitivity)</th>\n",
              "      <th>Specificity</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>MCC</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[[1485, 0], [0, 1517]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[[1485, 0], [0, 1517]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[[1485, 0], [0, 1517]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.989007</td>\n",
              "      <td>0.991391</td>\n",
              "      <td>0.986816</td>\n",
              "      <td>0.991246</td>\n",
              "      <td>0.989098</td>\n",
              "      <td>0.999629</td>\n",
              "      <td>0.978024</td>\n",
              "      <td>[[1472, 13], [20, 1497]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <td>0.920053</td>\n",
              "      <td>0.92652</td>\n",
              "      <td>0.914305</td>\n",
              "      <td>0.925926</td>\n",
              "      <td>0.920372</td>\n",
              "      <td>None</td>\n",
              "      <td>0.840186</td>\n",
              "      <td>[[1375, 110], [130, 1387]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K-Nearest Neighbors</th>\n",
              "      <td>0.796802</td>\n",
              "      <td>0.800132</td>\n",
              "      <td>0.796968</td>\n",
              "      <td>0.796633</td>\n",
              "      <td>0.798547</td>\n",
              "      <td>0.878995</td>\n",
              "      <td>0.59358</td>\n",
              "      <td>[[1183, 302], [308, 1209]]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Deep Neural Network</th>\n",
              "      <td>0.49467</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[[1485, 0], [1517, 0]]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ddeddba-65ae-4d86-91a6-84605ccda847')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ddeddba-65ae-4d86-91a6-84605ccda847 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ddeddba-65ae-4d86-91a6-84605ccda847');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5c7481d5-12c7-4780-86fe-684bf1722ba2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c7481d5-12c7-4780-86fe-684bf1722ba2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5c7481d5-12c7-4780-86fe-684bf1722ba2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fc232cb6-9aa8-45f1-b36f-c5930447b66d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df_1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fc232cb6-9aa8-45f1-b36f-c5930447b66d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df_1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df_1",
              "summary": "{\n  \"name\": \"results_df_1\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.49467021985343107,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9890073284477016,\n          0.49467021985343107,\n          0.9200532978014657\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.800132362673726,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9913907284768212,\n          0.800132362673726,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall (Sensitivity)\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.98681608437706,\n          0.0,\n          0.9143045484508899\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specificity\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.7966329966329966,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9912457912457913,\n          0.7966329966329966,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9890981169474727,\n          0.0,\n          0.920371599203716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC AUC\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.5,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0,\n          0.5,\n          0.9996293410927557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.978023888443507,\n          0.0,\n          0.8401857202651625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Confusion Matrix\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Observations:\n",
        "\n",
        "1. Random Forest, Gradient Boosting, AdaBoost gives well outstanding performance metrics\n",
        "2. Logistic Regression also nears to good metrics but it missed few true predictions\n",
        "3. Support Vector Machine marks up to 90% accuracy and missed out many true predictions\n",
        "4. K-nearest has only 80% accuracy and it missed out more than SVM true predictions\n",
        "5. DNN has the worst metrics in all models"
      ],
      "metadata": {
        "id": "ZOz1JzTOxTD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "wFkGDJfJcL4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation Steps for Model Training**\n",
        "\n",
        "\n",
        "#### **1. Import Required Libraries**\n",
        "   - **Purpose**: Import necessary libraries for machine learning and data processing.\n",
        "   - **Key Libraries**:\n",
        "     - `pandas`: For loading and manipulating the data.\n",
        "     - `scikit-learn`: For training the machine learning model (e.g., Logistic Regression).\n",
        "     - `train_test_split`: For splitting the data into training and testing sets.\n",
        "     - `accuracy_score`, `precision_score`, `recall_score`, `f1_score`: For evaluating model performance.\n",
        "\n",
        "   ```python\n",
        "   import pandas as pd\n",
        "   from sklearn.model_selection import train_test_split\n",
        "   from sklearn.linear_model import LogisticRegression\n",
        "   from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "   ```\n",
        "\n",
        "#### **2. Load the Preprocessed Data**\n",
        "   - **Purpose**: Load the preprocessed data (cleaned data) that was generated earlier from the **Data Preprocessing** step. This data contains both the Reddit posts and stock-related features.\n",
        "   - **Explanation**: This data will be used for training the model to predict stock market movements based on Reddit post sentiments.\n",
        "\n",
        "   ```python\n",
        "   df = pd.read_csv('reddit_stock_data_posts_cleaned.csv')\n",
        "   ```\n",
        "\n",
        "#### **3. Define Features and Target Variable**\n",
        "   - **Purpose**: Identify the independent (feature) variables and the dependent (target) variable.\n",
        "   - **Explanation**:\n",
        "     - The features (`X`) consist of various text-based features (like word count, sentiment scores) and stock-related data (like previous price changes, moving averages).\n",
        "     - The target variable (`y`) could be the **Price_Change** (whether the stock price changed positively or negatively).\n",
        "\n",
        "   ```python\n",
        "   X = df[['title_word_count', 'content_word_count', 'title_sentiment_score', 'content_sentiment_score', 'Prev_Price_Change']]\n",
        "   y = df['Price_Change']\n",
        "   ```\n",
        "\n",
        "#### **4. Split Data into Training and Testing Sets**\n",
        "   - **Purpose**: Divide the dataset into training and testing sets to evaluate the model's performance on unseen data.\n",
        "   - **Explanation**: The `train_test_split` function splits the data, typically using 80% for training and 20% for testing.\n",
        "\n",
        "   ```python\n",
        "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "   ```\n",
        "\n",
        "#### **5. Initialize the Model**\n",
        "   - **Purpose**: Create the machine learning model that will be trained using the training data.\n",
        "   - **Explanation**: The model in this case is a **Logistic Regression** model, which is commonly used for binary classification tasks. It predicts whether a stock's price will go up or down based on the features.\n",
        "\n",
        "   ```python\n",
        "   model = LogisticRegression()\n",
        "   ```\n",
        "\n",
        "#### **6. Train the Model**\n",
        "   - **Purpose**: Train the model using the training data (`X_train` and `y_train`).\n",
        "   - **Explanation**: The model learns patterns from the training data and adjusts its internal parameters to minimize errors in predictions. This is the core of the machine learning process.\n",
        "\n",
        "   ```python\n",
        "   model.fit(X_train, y_train)\n",
        "   ```\n",
        "\n",
        "#### **7. Make Predictions**\n",
        "   - **Purpose**: Use the trained model to predict the target variable (`Price_Change`) for the testing data (`X_test`).\n",
        "   - **Explanation**: The model will output predictions based on the features from the test set, which were not seen during training.\n",
        "\n",
        "   ```python\n",
        "   y_pred = model.predict(X_test)\n",
        "   ```\n",
        "\n",
        "#### **8. Evaluate the Model**\n",
        "   - **Purpose**: Assess the performance of the trained model by comparing its predictions with the actual target values from the testing set (`y_test`).\n",
        "   - **Explanation**: Evaluation metrics are calculated to gauge how well the model performed. These include:\n",
        "     - **Accuracy**: The proportion of correct predictions.\n",
        "     - **Precision**: The proportion of positive predictions that are actually positive.\n",
        "     - **Recall**: The proportion of actual positives that were correctly identified.\n",
        "     - **F1-score**: The harmonic mean of precision and recall.\n",
        "\n",
        "   ```python\n",
        "   accuracy = accuracy_score(y_test, y_pred)\n",
        "   precision = precision_score(y_test, y_pred)\n",
        "   recall = recall_score(y_test, y_pred)\n",
        "   f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "   print(f\"Accuracy: {accuracy}\")\n",
        "   print(f\"Precision: {precision}\")\n",
        "   print(f\"Recall: {recall}\")\n",
        "   print(f\"F1-score: {f1}\")\n",
        "   ```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "These explanation steps describe the entire process of how the **Model Training** script works, from importing libraries to training and evaluating the model. It provides a comprehensive understanding of the script's flow and how each section contributes to the overall goal."
      ],
      "metadata": {
        "id": "FJj8GUR4cD_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-ATyzqo82FPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking whether the model overfitting or not...."
      ],
      "metadata": {
        "id": "89WY0CS52Kdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Imports:\n",
        "\n",
        "    -> StratifiedKFold for splitting the dataset into stratified folds.\n",
        "    cross_val_score for performing cross-validation.\n",
        "\n",
        "    -> Metrics from sklearn.metrics for scoring functions.\n",
        "\n",
        "2. Cross-Validation Setup:\n",
        "\n",
        "    -> StratifiedKFold ensures the proportion of each class is consistent across all folds.\n",
        "\n",
        "    -> n_splits=5 divides the dataset into 5 folds.\n",
        "\n",
        "    -> shuffle=True ensures random shuffling of data before splitting.\n",
        "    \n",
        "    -> random_state=42 makes the process reproducible.\n",
        "\n",
        "3. Scoring Functions:\n",
        "\n",
        "    -> The scoring functions (accuracy, precision, recall, and F1-score) are pre-defined using make_scorer for compatibility with cross_val_score.\n",
        "\n",
        "    -> The zero_division=1 argument ensures no errors when a division by zero occurs in metrics like precision or recall.\n",
        "\n",
        "4. Cross-Validation for Each Model:\n",
        "\n",
        "    -> Loop over models in the models dictionary.\n",
        "\n",
        "    -> For each model, compute cross-validation scores for all metrics defined in scoring_functions.\n",
        "\n",
        "    -> Calculate the mean and standard deviation of the scores across the 5 folds.\n",
        "\n",
        "5. Results Storage:\n",
        "\n",
        "    Metrics are stored in a nested dictionary cv_results, where each model's results include the mean and standard deviation for all metrics.\n",
        "\n",
        "6. Summary Table:\n",
        "\n",
        "    The cv_results dictionary is converted into a Pandas DataFrame (cv_results_df) for easier viewing of results.\n"
      ],
      "metadata": {
        "id": "0o6ODXvEzPIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define Stratified K-Fold Cross-Validation (5 folds)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Dictionary to store the mean and standard deviation of each model's metrics\n",
        "cv_results = {}\n",
        "\n",
        "# Define scoring functions using make_scorer outside the loop\n",
        "scoring_functions = {\n",
        "    'Accuracy': make_scorer(accuracy_score),\n",
        "    'Precision': make_scorer(precision_score, zero_division=1),\n",
        "    'Recall': make_scorer(recall_score, zero_division=1),\n",
        "    'F1-Score': make_scorer(f1_score, zero_division=1)\n",
        "}\n",
        "\n",
        "\n",
        "# Evaluate each model using cross-validation\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{name} Cross-Validation Results:\")\n",
        "    cv_results[name] = {}\n",
        "\n",
        "    # Calculate and display metrics\n",
        "    for metric, scorer in scoring_functions.items():  # Use pre-defined scorers\n",
        "\n",
        "        # Perform cross-validation and calculate scores\n",
        "        scores = cross_val_score(model, X, y, cv=kf, scoring=scorer)\n",
        "        mean_score = np.mean(scores)\n",
        "        std_score = np.std(scores)\n",
        "\n",
        "        # Store results in the dictionary\n",
        "        cv_results[name][f\"{metric} Mean\"] = mean_score\n",
        "        cv_results[name][f\"{metric} Std\"] = std_score\n",
        "\n",
        "        # Print results for each metric\n",
        "        print(f\"{metric}: Mean = {mean_score:.4f}, Std = {std_score:.4f}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "# Convert the results dictionary into a DataFrame\n",
        "cv_results_df = pd.DataFrame(cv_results).T\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"\\nCross-Validation Summary:\")\n",
        "cv_results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KGMZ1pLC0DyJ",
        "outputId": "260fb00e-49e9-44e5-e186-bfe93365880c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Cross-Validation Results:\n",
            "Accuracy: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "Precision: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "Recall: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "F1-Score: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Gradient Boosting Cross-Validation Results:\n",
            "Accuracy: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "Precision: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "Recall: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "F1-Score: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "AdaBoost Cross-Validation Results:\n",
            "Accuracy: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "Precision: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "Recall: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "F1-Score: Mean = 1.0000, Std = 0.0000\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Logistic Regression Cross-Validation Results:\n",
            "Accuracy: Mean = 0.9880, Std = 0.0028\n",
            "--------------------------------------------------------------------------------\n",
            "Precision: Mean = 0.9870, Std = 0.0040\n",
            "--------------------------------------------------------------------------------\n",
            "Recall: Mean = 0.9891, Std = 0.0023\n",
            "--------------------------------------------------------------------------------\n",
            "F1-Score: Mean = 0.9880, Std = 0.0028\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Support Vector Machine Cross-Validation Results:\n",
            "Accuracy: Mean = 0.5592, Std = 0.0151\n",
            "--------------------------------------------------------------------------------\n",
            "Precision: Mean = 0.5775, Std = 0.0219\n",
            "--------------------------------------------------------------------------------\n",
            "Recall: Mean = 0.4446, Std = 0.0118\n",
            "--------------------------------------------------------------------------------\n",
            "F1-Score: Mean = 0.5022, Std = 0.0122\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "K-Nearest Neighbors Cross-Validation Results:\n",
            "Accuracy: Mean = 0.6559, Std = 0.0097\n",
            "--------------------------------------------------------------------------------\n",
            "Precision: Mean = 0.6455, Std = 0.0092\n",
            "--------------------------------------------------------------------------------\n",
            "Recall: Mean = 0.6919, Std = 0.0144\n",
            "--------------------------------------------------------------------------------\n",
            "F1-Score: Mean = 0.6678, Std = 0.0102\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Deep Neural Network Cross-Validation Results:\n",
            "Accuracy: Mean = 0.5000, Std = 0.0003\n",
            "--------------------------------------------------------------------------------\n",
            "Precision: Mean = 0.7013, Std = 0.2439\n",
            "--------------------------------------------------------------------------------\n",
            "Recall: Mean = 0.0749, Std = 0.1499\n",
            "--------------------------------------------------------------------------------\n",
            "F1-Score: Mean = 0.1333, Std = 0.2667\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cross-Validation Summary:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Accuracy Mean  Accuracy Std  Precision Mean  \\\n",
              "Random Forest                1.000000      0.000000        1.000000   \n",
              "Gradient Boosting            1.000000      0.000000        1.000000   \n",
              "AdaBoost                     1.000000      0.000000        1.000000   \n",
              "Logistic Regression          0.988007      0.002793        0.986980   \n",
              "Support Vector Machine       0.559165      0.015078        0.577496   \n",
              "K-Nearest Neighbors          0.655919      0.009736        0.645480   \n",
              "Deep Neural Network          0.500000      0.000298        0.701337   \n",
              "\n",
              "                        Precision Std  Recall Mean  Recall Std  F1-Score Mean  \\\n",
              "Random Forest                0.000000     1.000000    0.000000       1.000000   \n",
              "Gradient Boosting            0.000000     1.000000    0.000000       1.000000   \n",
              "AdaBoost                     0.000000     1.000000    0.000000       1.000000   \n",
              "Logistic Regression          0.004040     0.989072    0.002295       0.988022   \n",
              "Support Vector Machine       0.021940     0.444559    0.011803       0.502158   \n",
              "K-Nearest Neighbors          0.009154     0.691902    0.014445       0.667832   \n",
              "Deep Neural Network          0.243873     0.074933    0.149867       0.133333   \n",
              "\n",
              "                        F1-Score Std  \n",
              "Random Forest               0.000000  \n",
              "Gradient Boosting           0.000000  \n",
              "AdaBoost                    0.000000  \n",
              "Logistic Regression         0.002784  \n",
              "Support Vector Machine      0.012214  \n",
              "K-Nearest Neighbors         0.010190  \n",
              "Deep Neural Network         0.266667  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f63d82ff-ffae-4165-a816-f0fbad84f8f0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy Mean</th>\n",
              "      <th>Accuracy Std</th>\n",
              "      <th>Precision Mean</th>\n",
              "      <th>Precision Std</th>\n",
              "      <th>Recall Mean</th>\n",
              "      <th>Recall Std</th>\n",
              "      <th>F1-Score Mean</th>\n",
              "      <th>F1-Score Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.988007</td>\n",
              "      <td>0.002793</td>\n",
              "      <td>0.986980</td>\n",
              "      <td>0.004040</td>\n",
              "      <td>0.989072</td>\n",
              "      <td>0.002295</td>\n",
              "      <td>0.988022</td>\n",
              "      <td>0.002784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Machine</th>\n",
              "      <td>0.559165</td>\n",
              "      <td>0.015078</td>\n",
              "      <td>0.577496</td>\n",
              "      <td>0.021940</td>\n",
              "      <td>0.444559</td>\n",
              "      <td>0.011803</td>\n",
              "      <td>0.502158</td>\n",
              "      <td>0.012214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K-Nearest Neighbors</th>\n",
              "      <td>0.655919</td>\n",
              "      <td>0.009736</td>\n",
              "      <td>0.645480</td>\n",
              "      <td>0.009154</td>\n",
              "      <td>0.691902</td>\n",
              "      <td>0.014445</td>\n",
              "      <td>0.667832</td>\n",
              "      <td>0.010190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Deep Neural Network</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000298</td>\n",
              "      <td>0.701337</td>\n",
              "      <td>0.243873</td>\n",
              "      <td>0.074933</td>\n",
              "      <td>0.149867</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f63d82ff-ffae-4165-a816-f0fbad84f8f0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f63d82ff-ffae-4165-a816-f0fbad84f8f0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f63d82ff-ffae-4165-a816-f0fbad84f8f0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9affb348-21a6-4188-96f8-0de2c4986cea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9affb348-21a6-4188-96f8-0de2c4986cea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9affb348-21a6-4188-96f8-0de2c4986cea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d878e302-18a0-4552-9a22-9943cf9c3ff1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cv_results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d878e302-18a0-4552-9a22-9943cf9c3ff1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cv_results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cv_results_df",
              "summary": "{\n  \"name\": \"cv_results_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23187252970305705,\n        \"min\": 0.5,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9880069287141906,\n          0.5,\n          0.5591650011103708\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006038751100261841,\n        \"min\": 0.0,\n        \"max\": 0.01507846936483419,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0027934361619848906,\n          0.0002979437678214416,\n          0.01507846936483419\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19332050680110058,\n        \"min\": 0.5774961773884615,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9869796091191919,\n          0.7013373437316299,\n          0.5774961773884615\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09030959506111046,\n        \"min\": 0.0,\n        \"max\": 0.24387318744200814,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.004039592406490378,\n          0.24387318744200814,\n          0.0219398976111359\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36439213412691196,\n        \"min\": 0.07493333333333332,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9890719928983577,\n          0.07493333333333332,\n          0.44455854416333784\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05517561769632164,\n        \"min\": 0.0,\n        \"max\": 0.14986666666666665,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.002295201282244456,\n          0.14986666666666665,\n          0.011803348468159894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3396971876748965,\n        \"min\": 0.13333333333333333,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9880216124804111,\n          0.13333333333333333,\n          0.5021579121067139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09933392844237819,\n        \"min\": 0.0,\n        \"max\": 0.26666666666666666,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.002784387705977289,\n          0.26666666666666666,\n          0.012214230070703722\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations from the Cross-Validation Summary:\n",
        "\n",
        "1. **Ensemble Models Perform Perfectly**:\n",
        "   - **Random Forest**, **Gradient Boosting**, and **AdaBoost** achieve a perfect score (1.000) across all metrics.\n",
        "   - Observations:\n",
        "     - This might indicate either excellent model fitting or potential data leakage.\n",
        "     - Double-check preprocessing, cross-validation setup, and data splitting to ensure the models aren't being exposed to the test data during training.\n",
        "\n",
        "2. **Logistic Regression Performs Very Well**:\n",
        "   - **Accuracy Mean**: 0.988, with a low standard deviation (0.0028), indicating consistent performance across folds.\n",
        "   - **Precision Mean**: 0.987, **Recall Mean**: 0.989, and **F1-Score Mean**: 0.988.\n",
        "   - Observations:\n",
        "     - Logistic Regression demonstrates reliable and balanced performance.\n",
        "     - It's slightly behind the ensemble models but still very effective, likely due to feature scaling and regularization.\n",
        "\n",
        "3. **Support Vector Machine (SVM) Struggles**:\n",
        "   - **Accuracy Mean**: 0.559, **Precision Mean**: 0.577, **Recall Mean**: 0.445, and **F1-Score Mean**: 0.502.\n",
        "   - High standard deviations (e.g., **Precision Std**: 0.0219) indicate inconsistency across folds.\n",
        "   - Observations:\n",
        "     - SVM might not be suitable for this dataset or may require further tuning of hyperparameters (e.g., kernel type, C, and gamma values).\n",
        "     - Scaling has been applied, so other factors like class imbalance or feature relevance might need to be addressed.\n",
        "\n",
        "4. **K-Nearest Neighbors (KNN) Shows Moderate Performance**:\n",
        "   - **Accuracy Mean**: 0.656, **F1-Score Mean**: 0.668.\n",
        "   - Consistent performance with low standard deviations across metrics (e.g., **Accuracy Std**: 0.0097).\n",
        "   - Observations:\n",
        "     - KNN could benefit from tuning the number of neighbors (`n_neighbors`) and distance metrics.\n",
        "     - It performs slightly better than SVM but is not competitive with ensemble or logistic models.\n",
        "\n",
        "5. **Deep Neural Network (DNN) Performs Poorly**:\n",
        "   - **Accuracy Mean**: 0.500 (essentially random guessing).\n",
        "   - **Precision Mean**: 0.701, but extremely high standard deviation (0.2439), indicating unreliable predictions.\n",
        "   - **Recall Mean**: 0.075, **F1-Score Mean**: 0.133.\n",
        "   - Observations:\n",
        "     - The DNN fails to generalize, possibly due to:\n",
        "       - Insufficient training epochs.\n",
        "       - Suboptimal architecture (e.g., layer sizes, dropout rates, activation functions).\n",
        "       - The model might be underfitting or not learning effectively with the given dataset.\n",
        "     - Consider fine-tuning hyperparameters or increasing the size and quality of the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "yrkbeuP5ybzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saved the metrics and cross validation results into csv file for visulaization purpose...."
      ],
      "metadata": {
        "id": "x35L9UnXzzdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the results to a CSV file if needed\n",
        "results_df_1.to_csv(\"metrics_results.csv\", index=True)\n",
        "# Save the results to a CSV file if needed\n",
        "cv_results_df.to_csv(\"cross_validation_results.csv\", index=True)"
      ],
      "metadata": {
        "id": "URaIx3ZsaRfr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}